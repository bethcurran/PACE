{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d38dfe75-7f0d-4b19-a329-593f61552cc9",
   "metadata": {},
   "source": [
    "# ML4FLoods - Query Function Developement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4621878-9277-4e75-9f58-ef4ffe74f3a6",
   "metadata": {},
   "source": [
    "Authors: Beth Curran (Mitchell) and Christopher Rudolph\n",
    "\n",
    "Supervised by Cormac Purcell and Gonzalo Mateo-Garcia for Trillium Technologies. \n",
    "\n",
    "Original codebase by Gonzalo Mateo-Garcia https://github.com/spaceml-org/ml4floods/blob/0f8fdc4b6b891ed249f52fda19ee23c50462e237/ml4floods/data/ee_download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb878f58-93f3-4e73-99d7-1d5dd7ba122a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "Aim: To adapt and extend on code from ee_download.py in order to query avaliable Earth Engine data for a given AOI. Addressing deliverable **D1.1**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f78f54f-1440-439c-8563-6b899be337a4",
   "metadata": {},
   "source": [
    "**D1.1 Workflow to easily define event parameters (time-ranges, AOIs), query available satellite data and visualise satellite metadata.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e95291-7b28-49f2-88a6-ff7e1976c9a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Packages Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b00fc87-24d5-4ec6-8baa-da8d7f431e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/spaceml-org/ml4floods#egg=ml4floods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f915e7b-5b18-4e06-b0a4-70e12f65f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import warnings\n",
    "\n",
    "from io import StringIO\n",
    "import ee\n",
    "import time\n",
    "import os\n",
    "from glob import glob # not sure what this was used for -chris\n",
    "from typing import Optional, Callable, List, Tuple\n",
    "from shapely.geometry import mapping, Polygon\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import fsspec\n",
    "from datetime import datetime, timezone\n",
    "import math\n",
    "\n",
    "from ml4floods.data import ee_download, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9b3ca0-f6db-46fe-9e6c-9d18c8d57088",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting up Search Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee70c1e-8f9a-466b-b3b2-888d59fc0386",
   "metadata": {},
   "source": [
    "### Area of Interest (AOI) Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eba4f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the AOI \n",
    "\n",
    "#For the purposes on this workflow we are assuming the AOI is given as a file that is readable by geopandas\n",
    "def read_aoi(my_gpd_aoi:str):\n",
    "    my_aoi = gpd.read_file(my_gpd_aoi)\n",
    "    \n",
    "    aoi_codes = my_aoi['aoi_code']\n",
    "    js = json.loads(my_aoi.to_json()) # convertin gthe aoi to a json and getting the \n",
    "    \n",
    "    total_bounds = ee.Geometry(ee.FeatureCollection(js).geometry())\n",
    "    total_bound_coordinates = total_bounds.getInfo()['coordinates']\n",
    "    \n",
    "    n_polygons = len(total_bounds_coordinates)\n",
    "    \n",
    "    print('Number of polygons in AOI:', n_polygons)\n",
    "    \n",
    "    return total_bounds, aoi_codes, n_polygons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50865f6-c7b8-4b81-a95f-cfb192353515",
   "metadata": {},
   "source": [
    "### Desired Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b44681f-ee98-47dc-a04f-ae84d10ed618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifiying date of interest and converting to a variable to be passed, \n",
    "#inlcude year as a seperate variable for year long data (e.g. permanent water)\n",
    "\n",
    "#User to input dates with format 'dd/mm/yy' seperated by a comma. \n",
    "\n",
    "date_range = ('dd/mm/yy', 'dd/mm/yy')\n",
    "\n",
    "def get_datetime(date_range: tuple): # function returns a tuple containing datetime\n",
    "    datetime_start= datetime.strptime(date_range[0], '%d/%m/%y')\n",
    "    datetime_end= datetime.strptime(date_range[1], '%d/%m/%y')\n",
    "    \n",
    "    start_year = datetime_start.year\n",
    "    end_year = datetime_end.year\n",
    "    \n",
    "    return datetime_start, datetime_end, start_year, end_year "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf71e87-1fc4-48d6-9b9b-d680f384eff0",
   "metadata": {},
   "source": [
    "### Boundaries for each Polygon in AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01a2a8e5-f511-45ac-aaa5-409e66223747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a list of the bounds of the polygons, with a parameter for how many polygons you want to use. \n",
    "#The idea is that if you want all of them you can input the number printed from the 'read_aoi' function call.\n",
    "\n",
    "def get_polygon_bounds(total_bounds, aoi_codes, n_polygons):\n",
    "    # Get the coordinates for each AOI.\n",
    "    all_polygon_bounds = total_bounds.getInfo()['coordinates']\n",
    "\n",
    "    # Reducing the number of AOIs to n_polygons \n",
    "    polygon_aoi_codes = aoi_codes[0:n_polygons]\n",
    "\n",
    "    # Updating a list with the first 20 coordinates due to processing times. \n",
    "    polygon_bounds = []\n",
    "    for i in range(len(all_polygon_bounds[0:n_polygons])):\n",
    "      \n",
    "       polygon_bounds = np.append(polygon_bounds, ee.Geometry.Polygon(all_polygon_bounds[i]))\n",
    "                       \n",
    "    return polygon_bounds, polygon_aoi_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b431518-40c6-40c2-9e67-590a1f676f7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initial Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995a949-f556-4cea-98a7-dc697c0413fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reading in Data on Avaliable Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b45ee39-c365-4f3b-89ff-2c096b8863a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns arrays of imageCollections for each source (landsat and s2)\n",
    "\n",
    "def get_imageCollections(polygon_bounds: np.ndarray, dates: tuple): #bounds_list refers to a list of geometries/polygons extracted above from the aoi\n",
    "\n",
    "    get_landsat_collection = ee_download.get_landsat_collection\n",
    "    get_s2_collection = ee_download.get_s2_collection\n",
    "    \n",
    "    landsat_imgs = []\n",
    "    s2_imgs = []\n",
    "    \n",
    "    for i in range(len(polygon_bounds)):\n",
    "        landsat_imgs = np.append(landsat_imgs, get_landsat_collection(date_start=dates[0], date_end=dates[1] , bounds= polygon_bounds[i]))\n",
    "        s2_imgs = np.append(s2_imgs, get_s2_collection(date_start=dates[0], date_end=dates[1] , bounds= polygon_bounds[i]))\n",
    "\n",
    "    return landsat_imgs, s2_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd8f17d-f053-4800-b013-0ce67d6ac1a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extracting Relevant Properties from Data and Formatting into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce67b465-d29c-4000-9773-26a9f3b99f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def properties_dataframe(landsat_imgs: ee.ImageCollection, s2_imgs: ee.ImageCollection, polygon_bounds, polygon_aoi_codes):\n",
    "    # --------- Landsat ---------\n",
    "    landsat_coordinates = [[] for _ in range(len(landsat_imgs))] # creating number of lists to match the number of polygons so that each polygon will have it's coordinates\n",
    "    n_landsat = []\n",
    "\n",
    "    # Loop 1: Getting the number of images for each AOI, returns an array where each index is an \n",
    "    # AOI and each value in the index is the number of images of that AOI. \n",
    "    for i in range(len(landsat_imgs)):\n",
    "\n",
    "        # Get the coordinates for each AOI\n",
    "        landsat_coordinates[i] = polygon_bounds[i]['coordinates']\n",
    "\n",
    "        # Of the 20 indices, there will be the number of images in each. \n",
    "        n_landsat = np.append(n_landsat, len(landsat_imgs[i].getInfo()['features']))\n",
    "\n",
    "    # End loop 1\n",
    "\n",
    "    id_list = []\n",
    "    cloudCover_list = []\n",
    "    validPixels_list = []\n",
    "    source_list = ['landsat']*np.int(n_landsat.sum()) # creating a list the size of the total number of images of all the polygons\n",
    "    coordinates_list = [] # creating number of lists to match the number of polygons so that each polygon will have it's coordinates\n",
    "    aoi_list = []\n",
    "\n",
    "    # Loop 2: Updating property lists that will be used to populate a dataframe.\n",
    "    for i in range(len(landsat_imgs)): # Iterating through all the polygons\n",
    "\n",
    "        for k in range(np.int(n_landsat[i])): # Iterating through all the images of each polygon\n",
    "\n",
    "            id_list = np.append(id_list, landsat_imgs[i].getInfo()['features'][k].get('id'))\n",
    "            cloudCover_list = np.append(cloudCover_list, landsat_imgs[i].getInfo()['features'][k].get('properties')['CLOUD_COVER'])\n",
    "            validPixels_list = np.append(validPixels_list, landsat_imgs[i].getInfo()['features'][k].get('properties')['valids'])\n",
    "            aoi_list = np.append(aoi_list, polygon_aoi_codes[i])\n",
    "            index_coord = landsat_coordinates[i]\n",
    "            coordinates_list.extend(index_coord)      \n",
    "    # End loop 2\n",
    "\n",
    "    # Populate the dataframe\n",
    "    landsat_df = gpd.GeoDataFrame({'id':id_list, '%cloud_cvr':cloudCover_list, 'source': source_list, 'aoi_code': aoi_list, '%valid_pxl': validPixels_list, 'geometry':coordinates_list})\n",
    "    landsat_df.head(10)\n",
    "    print('Number of landsat images:', len(landsat_df))\n",
    "\n",
    "    # --------- S2 ---------\n",
    "    s2_coordinates = [[] for _ in range(len(s2_imgs))] # creating number of lists to match the number of polygons so that each polygon will have it's coordinates\n",
    "    n_s2 = []\n",
    "    \n",
    "    # Loop 1\n",
    "    for i in range(len(s2_imgs)): # Iterating through all the polygons\n",
    "\n",
    "        s2_coordinates[i] = polygon_bounds[i]['coordinates']\n",
    "\n",
    "        n_s2 = np.append(n_s2, len(s2_imgs[i].getInfo()['features'])) # Of the 20 indices, there will be the number of images in each. \n",
    "    # End loop 1\n",
    "\n",
    "    id_list = []\n",
    "    cloudCover_list = []\n",
    "    validPixels_list = []\n",
    "    source_list = ['s2']*np.int(n_s2.sum()) # creating a list the size of the total number of images of all the polygons\n",
    "    coordinates_list = [] # creating number of lists to match the number of polygons so that each polygon will have it's coordinates\n",
    "    aoi_list = []\n",
    "\n",
    "    # Loop 2\n",
    "    for i in range(len(s2_imgs)): # Iterating through all the polygons\n",
    "\n",
    "        for k in range(np.int(n_s2[i])): # Iterating through all the images of each polygon\n",
    "\n",
    "            id_list = np.append(id_list, s2_imgs[i].getInfo()['features'][k].get('id'))\n",
    "            cloudCover_list = np.append(cloudCover_list, s2_imgs[i].getInfo()['features'][k].get('properties')['CLOUDY_PIXEL_PERCENTAGE'])\n",
    "            validPixels_list = np.append(validPixels_list, s2_imgs[i].getInfo()['features'][k].get('properties')['valids'])\n",
    "            aoi_list = np.append(aoi_list, polygon_aoi_codes[i])\n",
    "            index_coord = s2_coordinates[i]\n",
    "            coordinates_list.extend(index_coord)      \n",
    "    # End loop 2\n",
    "\n",
    "    # Populate the dataframe\n",
    "    s2_df = gpd.GeoDataFrame({'id':id_list, '%cloud_cvr':cloudCover_list, 'source': source_list, 'aoi_code': aoi_list, '%valid_pxl': validPixels_list, 'geometry':coordinates_list})\n",
    "    s2_df.head(10)\n",
    "    print('Number of s2 images:', len(s2_df))\n",
    "    \n",
    "    # Combining into one dataframe, assigning crs and formatting geometry column for plotting\n",
    "    \n",
    "    all_df = pd.concat([landsat_df, s2_df])\n",
    "    \n",
    "    all_df.crs = 'EPSG:4326'\n",
    "    \n",
    "    all_df['geometry'] = all_df['geometry'].apply(Polygon)\n",
    "    \n",
    "    print('Total number of images:', len(all_df))\n",
    "          \n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ed2c09-89df-479a-a821-89e1e1a814e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Appendix 1: Previous versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d281ccb6-d0b5-4b10-a298-512324dd367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first attempt at a function to produce a dataframe of properties. This did work but we found that it was inefficient for looping over multiple polygons. \n",
    "\n",
    "def extract_properties(landsat_imgs, s2_imgs, init_bounds, aoi_code):\n",
    "    \n",
    "    coordinates = init_bounds['coordinates']\n",
    "    \n",
    "    landsat_dict = landsat_imgs.getInfo()\n",
    "    s2_dict = s2_imgs.getInfo()\n",
    "    \n",
    "    n_landsat = len(landsat_dict['features'])\n",
    "    print('Landsat images:', n_landsat)\n",
    "    n_s2 = len(s2_dict['features'])\n",
    "    print('s2 images:', n_s2)\n",
    "    \n",
    "    n_total = n_landsat + n_s2 \n",
    "    \n",
    "    properties_df = pd.DataFrame(index=np.arange(0, n_total), columns=['id', 'source', 'cloud_cover', 'percentage_valid_pixels', 'coordinates', 'aoi_code']) \n",
    "    \n",
    "    \n",
    "    for i in range(n_landsat):\n",
    "        properties_df['id'][i] = landsat_dict['features'][i].get('id')\n",
    "        properties_df['source'][i] = 'landsat'\n",
    "        properties_df['cloud_cover'][i] = landsat_dict['features'][i].get('properties')['CLOUD_COVER']\n",
    "        properties_df['percentage_valid_pixels'][i] = landsat_dict['features'][i].get('properties')['valids'] \n",
    "        properties_df['coordinates'][i] = coordinates\n",
    "        properties_df['aoi_code'][i] = aoi_code\n",
    "        #find area/co-ordinates associated with each image\n",
    "        \n",
    "    for i in range(n_s2):\n",
    "        j = i + n_landsat\n",
    "        properties_df['id'][j] = s2_dict['features'][i].get('id')\n",
    "        properties_df['source'][j] = 's2'\n",
    "        properties_df['cloud_cover'][j] = s2_dict['features'][i].get('properties')['CLOUD_COVERAGE_ASSESSMENT']\n",
    "        properties_df['percentage_valid_pixels'][j] = s2_dict['features'][i].get('properties')['valids'] \n",
    "        properties_df['coordinates'][j] = coordinates\n",
    "        properties_df['aoi_code'][j] = aoi_code\n",
    "        #find area/co-ordinates associated with each image\n",
    "    \n",
    "    return properties_df"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
